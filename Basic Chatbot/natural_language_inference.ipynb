{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import sys\n",
    "\n",
    "def gpu_check():\n",
    "    try:\n",
    "        output = subprocess.check_output('nvidia-smi', shell=True).decode('utf-8')\n",
    "        if \"No devices were found\" in output:\n",
    "            print(\"No GPU detected. Exiting.\")\n",
    "            sys.exit(1)\n",
    "        elif \"%\" in output:\n",
    "            print(\"GPU detected and being used.\")\n",
    "        else:\n",
    "            print(\"GPU is detected but not being used. Exiting.\")\n",
    "            sys.exit(1)\n",
    "    except subprocess.CalledProcessError:\n",
    "        print(\"Unable to check GPU status. Exiting.\")\n",
    "        sys.exit(1)\n",
    "\n",
    "questions = [\n",
    "    # Business Details\n",
    "    \"What is the elevator pitch?\",\n",
    "    \"What problem is the company solving?\",\n",
    "    \"What is the company's solution to the problem they are solving?\",\n",
    "    \"How is the company's solution defensible in the marketplace?\",\n",
    "    \"What are the patent details?\",\n",
    "    \"What risks does the company face?\",\n",
    "    \"How did the company discover their customers?\",\n",
    "    \"What is the customer description?\",\n",
    "    \"What is the customer acquisition strategy?\",\n",
    "    \"What is the company's revenue model?\",\n",
    "    \"What is the market opportunity for the company?\",\n",
    "    \"What is the company's competitive landscape?\",\n",
    "]\n",
    "\n",
    "description = \"\"\"\n",
    "At 'TerrorToys', we specialize in crafting the most thrillingly dangerous toys the world has ever seen. Forget the mundane plastic dolls and stuffed animals; we create toys that push the boundaries of fun — and fear. From remote-controlled mini-tanks equipped with miniature flamethrowers, to interactive robots with sharp metal claws, our toys are engineered to thrill, shock, and sometimes, even harm. We blend cutting-edge technology with raw, menacing designs, ensuring that each product is as dangerous as it is exciting. Whether it’s a “Creeper Claw” action figure that can spring to life with a terrifying hiss or a “Doomsday Drone” that flies with the ability to launch mini explosives, our toys are the ultimate adrenaline rush for those brave enough to play.\n",
    "\n",
    "But what truly sets us apart from other toy manufacturers is our elite marketing team — a group of creative minds that have mastered the art of spin. While the safety-conscious masses recoil at the idea of a toy that can seriously injure, our marketing geniuses spin these concerns into selling points. Through carefully crafted ads, they position our toys as “extreme experiences” rather than hazardous products. Our slogans like “Unleash the Chaos” and “For Kids Who Like Their Fun Dangerous” resonate with a rebellious crowd looking for thrills. In a world of soft, sanitized entertainment, we sell the thrill of unpredictability and a touch of danger — a rare commodity in today’s climate of over-protection.\n",
    "\n",
    "The marketing team knows exactly who to target. With strategic placements in extreme sports media, horror movie forums, and underground gaming communities, they’ve created a fanbase of fearless thrill-seekers. Social media campaigns highlight real-life “missions” where our toys play a starring role, often featuring high-energy stunts or daring challenges. Our toy launches often coincide with viral stunts that leave the world buzzing with excitement. Clever partnerships with influencers who enjoy pushing the limits — such as skydivers, stunt artists, and even extreme chefs — bring our toys into the limelight. \n",
    "\n",
    "Moreover, we’ve learned how to cleverly avoid liability issues by framing our products as novelty items for collectors. Through limited editions and exclusivity, the toys are portrayed as rare artifacts for the bold few. This tactic generates a sense of scarcity, increasing the demand among risk-takers who want to possess a piece of true danger. At *TerrorToys*, danger isn’t just a feature — it’s the selling point, expertly marketed to those who crave the unpredictable.\n",
    "\"\"\"\n",
    "\n",
    "description = \"\"\"\n",
    "Investor Brief \n",
    "First textile sorting and processing plant in \n",
    "North America.  \n",
    "Early-Stage Textile Industry Startup  \n",
    "Specializing in End-of-Life Apparel Recycling \n",
    "Delaware C Corporation; Est. Sep. 2020 \n",
    "Operating in North Carolina, USA \n",
    "Mission: To accelerate circularity in the textile \n",
    "industry.  \n",
    "Kerem Saral, CEO-Founder \n",
    "20 years in the textile industry with a \n",
    "concentration in sustainability, raw material trade \n",
    "and recycling.    \n",
    "kerem@cirtexcorp.com \n",
    "www.cirtexcorp.com \n",
    "+1-980-201-6746 \n",
    "Advisory Board: \n",
    "Name \n",
    "Expertise Area \n",
    "Merrilee Avila \n",
    "Apparel \n",
    "Retail/Brand \n",
    "Sustainability \n",
    "Marisa Adler \n",
    "Solid Waste \n",
    "Management \n",
    "Textile \n",
    "Recovery \n",
    "Karim Zakkour Grading & \n",
    "Traci Kinden \n",
    "Re-Sale \n",
    "Circular \n",
    "Textiles \n",
    "Used Clothing \n",
    "Collection \n",
    "Recycling \n",
    "Feedstock \n",
    "Patrick Mullen \n",
    "Operations \n",
    "Textile Waste \n",
    "Processing \n",
    "Bill Ballenden \n",
    "Cotton Trade Commodity \n",
    "Markets \n",
    "Janel Twogood Industrial \n",
    "Design \n",
    "Circular \n",
    "Textiles \n",
    "Early-Stage Startup Advisor: \n",
    "Colene McBeth \n",
    "Launch Lake Norman Mentorship Program: \n",
    "Tom Maupin - Finance & Management \n",
    "Terry Pardue - Corporate Finance  \n",
    "Financial Advisors:  \n",
    "Deniz Saral, PhD – Business Administration \n",
    "Mehmet Sami – M&A and Financial Advisor \n",
    "Industry Involvement: \n",
    "Accelerating Circularity Project (ACP) \n",
    "Textile Exchange r-PET round table  \n",
    "Sustainable Furnishings Council \n",
    "Total Funding Needs: $2,000,000 \n",
    "Funds are needed to set up the first CirTex facility \n",
    "in the US. This will also the be the first automated \n",
    "textile sorting and process plant in North America.  \n",
    "Use of Funds:    \n",
    "Startup Costs: \n",
    "Working capital: \n",
    "Capex:  \n",
    "Investments to date: \n",
    "Seed from angel: \n",
    "Own savings: \n",
    "$100,000 \n",
    "$400,000 \n",
    "$1,500,000 \n",
    "$20,000 \n",
    "$30,000 \n",
    "Reasons for Investing:  \n",
    "Social enterprise focused on sustainability and \n",
    "environmental impact reduction \n",
    "New generation textile supply chain actor driven by \n",
    "innovation and technology \n",
    "U \n",
    "Operational model with a low initial cash burn and \n",
    "rapid operating profit \n",
    "Proven business model resulting in firm \n",
    "commitments from brands and off-takers and in \n",
    "secured revenue streams \n",
    "Background: Fast fashion has made shopping for clothes affordable, but this has come at a \n",
    "detrimental cost to the environment. Staggering growth rates and the subsequent waste generated \n",
    "by its linear take-make-dispose model has made the textile industry one of the most toxic today. It’s \n",
    "estimated that 85% of all clothes end up in landfills, incineration centers or directly in our \n",
    "environment. This needs to stop.  \n",
    "The Textile Industry Accounts For \n",
    "CO2\n",
    " ~8%\n",
    " of global CO  emissions\n",
    " 2\n",
    " 20%\n",
    " of global industrial\n",
    " wastewater generation\n",
    " 4%\n",
    " of global fresh\n",
    " water withdrawal\n",
    " 34%\n",
    " of global microfiber\n",
    " released into the ocean\n",
    " To lower its environmental impact, the industry is attempting to switch from a linear to a circular \n",
    "model where recycling is a key component. Recent developments in chemical recycling have \n",
    "established a reliable pathway for production of virgin grade fibers from used cotton, polyester, and \n",
    "cotton-polyester blended textiles. The recycling capacity using these new technologies is scaling. \n",
    "However, despite these important research developments, a systematic change towards \n",
    "creating circularity where end-of-life apparel can be recycled into new raw materials is still \n",
    "not possible.  \n",
    "Problem: Lack of Infrastructure. New chemical recycling technologies require feedstock to have \n",
    "precise fiber contents and to be free of non-textile components. This means that before end-of-life \n",
    "clothes can be chemically recycled, they must be accurately sorted by fiber content and be processed \n",
    "to remove all zippers and buttons. Proper sorting and processing of used clothes is an \n",
    "essential step for chemical textile recycling, yet the infrastructure needed to perform this \n",
    "step is missing entirely.  \n",
    "Solution: CirTex has an automated, scalable process that streamlines sorting and \n",
    "processing of used clothes to close the gap in textile recycling infrastructure. Using mixed \n",
    "apparel as inputs, CirTex can recover the recyclable cotton and polyester clothes and process these \n",
    "sorted materials into ready-to-recycle feedstock. A single CirTex facility can convert 21,000 tons of \n",
    "end-of-life apparel into recycling feedstock annually.  \n",
    "Market Size: Multi-billion-dollar market with an estimated 35% CAGR. With an estimated \n",
    "production of 146 million tons of fibers, the global textile fibers market is expected to reach $1.5 \n",
    "trillion by 2030. Driven by policy and brand commitments, “textile-to-textile (t-2-t) recycled fibers” is \n",
    "expected to be the fastest growing segment of this market. CirTex will sell feedstock to producers \n",
    "(recyclers) in this segment. If barriers to scale can be removed, such as the sorting and processing \n",
    "infrastructure gap, this feedstock market could grow at 35% CAGR and reach nearly $900 million by \n",
    "2025 and exceed $2 billion by 2030. CirTex is targeting a market share of 1.5% by 2025 and 2.15% \n",
    "by 2030.  \n",
    "Traction: We partnered with two NYSE-listed multinational brands in two distinct pilots and engaged \n",
    "with key industry players to create the following traction in our early startup phase: \n",
    "• Identified recyclable clothing categories and the best recycling method for each category \n",
    "• Worked with academic research institutions and industry leader manufacturers to \n",
    "demonstrate product end-use compatibility for both recyclables and non-recyclables \n",
    "• Validated business model through firm commitments from off-takers and suppliers  \n",
    "• Generated proof of concept for CirTex’s process  \n",
    "• Consolidated, processed, and traded 130 tons of pre-consumer and post-consumer mixed \n",
    "apparels and 180 tons of cotton thread waste \n",
    "The Team: CirTex is guided by a team of experts with 140 years of combined industry experience \n",
    "covering apparel retailer and brand business, waste, commodities and raw material trade, municipal \n",
    "waste management, circularity, sustainability, recycling and textile waste processing. In addition, it \n",
    "receives financial and business development advice from several qualified individuals with decades of \n",
    "experience in the fields of corporate finance, M&A, operations, management and business \n",
    "administration.  \n",
    "Business Model: Using different service offers, we will work with retailers, brands, re-sale \n",
    "businesses, collectors, graders and charities to secure our inputs. We expect a mixed cost structure \n",
    "for our inputs with a target average landed cost. Our primary revenue streams will be generated from \n",
    "the sale of our cotton and polyester feedstocks to our recycling partners. The sale of non-recyclables \n",
    "to nonwoven fiber producer partners will generate a secondary revenue stream. We aim to convert \n",
    "materials we cannot utilize into alternative fuel to achieve a zero-landfill operation.  \n",
    "Fast growth potential  \n",
    "Competition: Today, only few European companies have automated textile sorting capability. Out of these few, \n",
    "only Sysav (Sweden) and Lounais-Suomen Jätehuolto (Finland), which are municipality-owned waste management \n",
    "companies, have the sorting capabilities that CirTex aspires to have. Competition can be segmented as follows: \n",
    "1. Existing Textile Recyclers \n",
    "Activities: Integrated manual sorting and manual processing combined with mechanical recycling \n",
    "Examples: Recover (Spain/North Africa), Giotex (Mexico), Gama (Turkey), A-One Graders (Pakistan) \n",
    "2. Collectors and Graders of Used Clothes  \n",
    "Activities: Collection of used clothes, manual categorization by functionality for re-sale. \n",
    "Examples: I:CO and Soex (Germany), Texaid (Switzerland), Goodwill (USA), Bank & Vogue (Canada) \n",
    "3. Waste Management Companies \n",
    "Activities: Collection of solid wastes and recyclables, commoditization of recyclables by material type \n",
    "Examples: Waste Management (USA), Sysav (Sweden), Lounais-Suomen Jätehuolto (Finland) \n",
    "Existing textile recyclers have business models based on mechanical recycling, not chemical recycling. \n",
    "Collectors and graders are re-sale specialists and don’t have the precision-sorting capabilities required for \n",
    "chemical recycling. Waste management companies, despite having access to capital and sorting know-how, \n",
    "mostly specialize in residential and post-industrial wastes. They are also textile industry outsiders. Sysav and \n",
    "Lounais-Suomen Jätehuolto operate outside the US and are very unlikely to expand into the US market.   \n",
    "Value Proposition: Why can CirTex compete and win?  \n",
    "• High Precision Products at Competitive Prices: We’re innovation and technology driven. Using sorters \n",
    "with integrated NIR technology, CirTex’s automated process efficiently produces outputs with precise fiber \n",
    "contents at scale and at competitive prices compared to old-school companies using a manual approach.   \n",
    "• Dual Industry Expertise: Our experience, knowledge, and existing relationships in both the apparel and \n",
    "the recycling industries allow us to bridge the gap between the two and meet the needs of both our \n",
    "suppliers and customers. \n",
    "• Undivided Focus: Sorting and processing apparel for recycling is CirTex’s sole focus and core business. \n",
    "We will be the best-in-business in doing this.  \n",
    "• Proven Business Model: As a result of our pilots and multistakeholder approach to industry engagement \n",
    "for the past year and a half, we were able to secure off-taker commitments from two new generation \n",
    "recyclers, as well as letters of intent (LoI) with two large brands and a large-scale a re-sale specialist. \n",
    "These commitments allow us to secure enough supplies and revenue streams to jump start our operations \n",
    "and put CirTex on a good trajectory to be first-in-market in North America.  \n",
    "SDGs & CirTex: As a new generation textile supply chain actor and as part of the international sustainability \n",
    "community, our company will contribute to the following U.N. Sustainable Development Goals. \n",
    "Key Financial Figures for the First CirTex Facility (in 000s):\n",
    " Y1 \n",
    "Total Net Sales \n",
    "$ 972 \n",
    "Y2 \n",
    "Y3* \n",
    "$ 4,277 \n",
    "COGS \n",
    "$ 753 \n",
    "$ 5,203 \n",
    "$ 1,865 \n",
    "Gross Margin \n",
    "$ 219 \n",
    "$ 2,222 \n",
    "$ 2,411 \n",
    "Operating Expenses \n",
    "$ 416 \n",
    "$ 2,981 \n",
    "$ 804 \n",
    "EBITDA \n",
    "$ (196) \n",
    "$ 805 \n",
    "$ 1,607 \n",
    "Gross Margin Ratio \n",
    "12% \n",
    "$ 2,175 \n",
    "27% \n",
    "Long-Term Vision: \n",
    "40% \n",
    "Opex/Sales \n",
    "Total Headcount \n",
    "43% \n",
    "19% \n",
    "10 \n",
    "20 \n",
    "15% \n",
    "20 \n",
    "*The first CirTex facility has a 2-year scale up plan to reach full \n",
    "capacity in Q4 of Y2. Cashflows of Y3 reflect the expected \n",
    "cashflows of all consecutive years.  \n",
    "The first CirTex facility will serve as a blueprint for \n",
    "integrating automated sorting and processing of \n",
    "mixed apparel for recycling end-use. Our vision is to \n",
    "expand the business by copying and pasting this \n",
    "blueprint in multiple locations in the US and around \n",
    "the world. Our aim is to have 10 CirTex facilities and \n",
    "to reach $50 million of total net sales by 2030.\n",
    "\"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python312\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_community\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mchat_models\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ChatOllama\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m pipeline\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgenerate_answers\u001b[39m(description, questions):\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1412\u001b[0m, in \u001b[0;36m_handle_fromlist\u001b[1;34m(module, fromlist, import_, recursive)\u001b[0m\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\transformers\\utils\\import_utils.py:1766\u001b[0m, in \u001b[0;36m_LazyModule.__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   1764\u001b[0m     value \u001b[38;5;241m=\u001b[39m Placeholder\n\u001b[0;32m   1765\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_class_to_module\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m-> 1766\u001b[0m     module \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_module\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_class_to_module\u001b[49m\u001b[43m[\u001b[49m\u001b[43mname\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1767\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(module, name)\n\u001b[0;32m   1768\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_modules:\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\transformers\\utils\\import_utils.py:1778\u001b[0m, in \u001b[0;36m_LazyModule._get_module\u001b[1;34m(self, module_name)\u001b[0m\n\u001b[0;32m   1776\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_get_module\u001b[39m(\u001b[38;5;28mself\u001b[39m, module_name: \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m   1777\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1778\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mimportlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimport_module\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m.\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmodule_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__name__\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1779\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m   1780\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m   1781\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to import \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodule_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m because of the following error (look up to see its\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1782\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m traceback):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1783\u001b[0m         ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\importlib\\__init__.py:90\u001b[0m, in \u001b[0;36mimport_module\u001b[1;34m(name, package)\u001b[0m\n\u001b[0;32m     88\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m     89\u001b[0m         level \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m---> 90\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_bootstrap\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_gcd_import\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpackage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\transformers\\pipelines\\__init__.py:26\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdynamic_module_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_class_from_dynamic_module\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfeature_extraction_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PreTrainedFeatureExtractor\n\u001b[1;32m---> 26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mimage_processing_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BaseImageProcessor\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mauto\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconfiguration_auto\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AutoConfig\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mauto\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfeature_extraction_auto\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m FEATURE_EXTRACTOR_MAPPING, AutoFeatureExtractor\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\transformers\\image_processing_utils.py:21\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mimage_processing_base\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BatchFeature, ImageProcessingMixin\n\u001b[1;32m---> 21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mimage_transforms\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m center_crop, normalize, rescale\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mimage_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ChannelDimension\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m logging\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\transformers\\image_transforms.py:22\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Iterable, List, Optional, Tuple, Union\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m---> 22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mimage_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     23\u001b[0m     ChannelDimension,\n\u001b[0;32m     24\u001b[0m     ImageInput,\n\u001b[0;32m     25\u001b[0m     get_channel_dimension_axis,\n\u001b[0;32m     26\u001b[0m     get_image_size,\n\u001b[0;32m     27\u001b[0m     infer_channel_dimension_format,\n\u001b[0;32m     28\u001b[0m )\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ExplicitEnum, TensorType, is_jax_tensor, is_tf_tensor, is_torch_tensor\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mimport_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     31\u001b[0m     is_flax_available,\n\u001b[0;32m     32\u001b[0m     is_tf_available,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     37\u001b[0m     requires_backends,\n\u001b[0;32m     38\u001b[0m )\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\transformers\\image_utils.py:58\u001b[0m\n\u001b[0;32m     55\u001b[0m         PILImageResampling \u001b[38;5;241m=\u001b[39m PIL\u001b[38;5;241m.\u001b[39mImage\n\u001b[0;32m     57\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_torchvision_available():\n\u001b[1;32m---> 58\u001b[0m         \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorchvision\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtransforms\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m InterpolationMode\n\u001b[0;32m     60\u001b[0m         pil_torch_interpolation_mapping \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m     61\u001b[0m             PILImageResampling\u001b[38;5;241m.\u001b[39mNEAREST: InterpolationMode\u001b[38;5;241m.\u001b[39mNEAREST,\n\u001b[0;32m     62\u001b[0m             PILImageResampling\u001b[38;5;241m.\u001b[39mBOX: InterpolationMode\u001b[38;5;241m.\u001b[39mBOX,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     66\u001b[0m             PILImageResampling\u001b[38;5;241m.\u001b[39mLANCZOS: InterpolationMode\u001b[38;5;241m.\u001b[39mLANCZOS,\n\u001b[0;32m     67\u001b[0m         }\n\u001b[0;32m     70\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m TYPE_CHECKING:\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\torchvision\\__init__.py:6\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmodulefinder\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Module\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorchvision\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _meta_registrations, datasets, io, models, ops, transforms, utils\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mextension\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _HAS_OPS\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\torchvision\\models\\__init__.py:2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01malexnet\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconvnext\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdensenet\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mefficientnet\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\torchvision\\models\\convnext.py:8\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m nn, Tensor\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m functional \u001b[38;5;28;01mas\u001b[39;00m F\n\u001b[1;32m----> 8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmisc\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Conv2dNormActivation, Permute\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mstochastic_depth\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m StochasticDepth\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtransforms\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_presets\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ImageClassification\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\torchvision\\ops\\__init__.py:23\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgiou_loss\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m generalized_box_iou_loss\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmisc\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Conv2dNormActivation, Conv3dNormActivation, FrozenBatchNorm2d, MLP, Permute, SqueezeExcitation\n\u001b[1;32m---> 23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpoolers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m MultiScaleRoIAlign\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mps_roi_align\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ps_roi_align, PSRoIAlign\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mps_roi_pool\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ps_roi_pool, PSRoIPool\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\torchvision\\ops\\poolers.py:10\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorchvision\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mboxes\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m box_area\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _log_api_usage_once\n\u001b[1;32m---> 10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mroi_align\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m roi_align\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# copying result_idx_in_level to a specific index in result[]\u001b[39;00m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# is not supported by ONNX tracing yet.\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# _onnx_merge_levels() is an implementation supported by ONNX\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# that merges the levels to the right indices\u001b[39;00m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;129m@torch\u001b[39m\u001b[38;5;241m.\u001b[39mjit\u001b[38;5;241m.\u001b[39munused\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_onnx_merge_levels\u001b[39m(levels: Tensor, unmerged_results: List[Tensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\torchvision\\ops\\roi_align.py:4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m List, Union\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_dynamo\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfx\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m nn, Tensor\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\torch\\_dynamo\\__init__.py:2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m allowed_functions, convert_frame, eval_frame, resume_execution\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbackends\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mregistry\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m list_backends, lookup_backend, register_backend\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcode_context\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m code_context\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:64\u001b[0m\n\u001b[0;32m     62\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01moutput_graph\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m OutputGraph\n\u001b[0;32m     63\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mreplay_record\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ExecutionRecord\n\u001b[1;32m---> 64\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msymbolic_convert\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m InstructionTranslator, SpeculationLog\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtypes\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BytecodeHook\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     67\u001b[0m     CleanupManager,\n\u001b[0;32m     68\u001b[0m     CompilationMetrics,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     83\u001b[0m     write_record_to_file,\n\u001b[0;32m     84\u001b[0m )\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py:59\u001b[0m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01moutput_graph\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m GraphCompileReason, OutputGraph, OutputGraphState\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mreplay_record\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DummyModule, ExecutionRecorder\n\u001b[1;32m---> 59\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mresume_execution\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ContinueExecutionCache, ReenterWith\n\u001b[0;32m     60\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msource\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     61\u001b[0m     AttrSource,\n\u001b[0;32m     62\u001b[0m     GetItemSource,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     66\u001b[0m     Source,\n\u001b[0;32m     67\u001b[0m )\n\u001b[0;32m     68\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     69\u001b[0m     counters,\n\u001b[0;32m     70\u001b[0m     get_fake_value,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     75\u001b[0m     proxy_args_kwargs,\n\u001b[0;32m     76\u001b[0m )\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1360\u001b[0m, in \u001b[0;36m_find_and_load\u001b[1;34m(name, import_)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1322\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[1;34m(name, import_)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1262\u001b[0m, in \u001b[0;36m_find_spec\u001b[1;34m(name, path, target)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap_external>:1525\u001b[0m, in \u001b[0;36mfind_spec\u001b[1;34m(cls, fullname, path, target)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap_external>:1499\u001b[0m, in \u001b[0;36m_get_spec\u001b[1;34m(cls, fullname, path, target)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap_external>:1631\u001b[0m, in \u001b[0;36mfind_spec\u001b[1;34m(self, fullname, target)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap_external>:161\u001b[0m, in \u001b[0;36m_path_isfile\u001b[1;34m(path)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap_external>:153\u001b[0m, in \u001b[0;36m_path_is_mode_type\u001b[1;34m(path, mode)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap_external>:147\u001b[0m, in \u001b[0;36m_path_stat\u001b[1;34m(path)\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from langchain_community.chat_models import ChatOllama\n",
    "from transformers import pipeline\n",
    "import torch\n",
    "\n",
    "def generate_answers(description, questions):\n",
    "    llm = ChatOllama(model=\"llama3.1\", device=\"cuda\", temperature=0)\n",
    "    nli_model = pipeline(\"zero-shot-classification\", model=\"facebook/bart-large-mnli\", device=0 if torch.cuda.is_available() else -1)\n",
    "    answers = []\n",
    "\n",
    "    try:\n",
    "        for question in questions:\n",
    "            prompt = f\"\"\"\n",
    "            Company Description: \"\"{description}\"\"\n",
    "\n",
    "            Question: \"\"{question}\"\"\n",
    "\n",
    "            FOLLOW THESE REQUIREMENTS:\n",
    "            - Please provide a concise and relevant answer to the question based on the company description as if you are the company representative answering it.\n",
    "            - Do not say you are 'attempting' to answer the question or provide any other disclaimers.\n",
    "            - Do not make any references to yourself.\n",
    "            - If you do not have enough information to answer the question, output 'Information not provided'.\n",
    "            - If you are not sure about specific technical details, avoid making them up or mentioning them. If you lack enough details that you cannot provide an answer firmly based in the company description, output 'Information not provided'.\n",
    "            - Simply provide the answer in passive voice as if you are the company representative.\n",
    "            - Everything should be in plain text. Do not include any formatting or special characters.\n",
    "            - Be descriptive and provide concrete detail.\n",
    "            \"\"\"\n",
    "            answer = llm.invoke(prompt).content\n",
    "\n",
    "            # NLI check\n",
    "            nli_result = nli_model(answer, [description], hypothesis_template=\"This text is true: {}\")\n",
    "            print(nli_result)\n",
    "            print()\n",
    "            print(nli_result['scores'])\n",
    "            print()\n",
    "            print(nli_result['labels'])\n",
    "            print()\n",
    "            entailment_score = nli_result['scores'][0]\n",
    "\n",
    "            if entailment_score < 0.9:  # Adjust this threshold as needed\n",
    "                answer = \"Information not provided\"\n",
    "\n",
    "            answers.append(answer)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        answers = [\"Error generating answer\" for _ in questions]\n",
    "\n",
    "    return answers\n",
    "\n",
    "gpu_check()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (2885 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA error: device-side assert triggered\n",
      "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
      "For debugging consider passing CUDA_LAUNCH_BLOCKING=1.\n",
      "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
      "\n",
      "Question: What is the elevator pitch?\n",
      "Answer: Error generating answer\n",
      "\n",
      "Question: What problem is the company solving?\n",
      "Answer: Error generating answer\n",
      "\n",
      "Question: What is the company's solution to the problem they are solving?\n",
      "Answer: Error generating answer\n",
      "\n",
      "Question: How is the company's solution defensible in the marketplace?\n",
      "Answer: Error generating answer\n",
      "\n",
      "Question: What are the patent details?\n",
      "Answer: Error generating answer\n",
      "\n",
      "Question: What risks does the company face?\n",
      "Answer: Error generating answer\n",
      "\n",
      "Question: How did the company discover their customers?\n",
      "Answer: Error generating answer\n",
      "\n",
      "Question: What is the customer description?\n",
      "Answer: Error generating answer\n",
      "\n",
      "Question: What is the customer acquisition strategy?\n",
      "Answer: Error generating answer\n",
      "\n",
      "Question: What is the company's revenue model?\n",
      "Answer: Error generating answer\n",
      "\n",
      "Question: What is the market opportunity for the company?\n",
      "Answer: Error generating answer\n",
      "\n",
      "Question: What is the company's competitive landscape?\n",
      "Answer: Error generating answer\n",
      "\n"
     ]
    }
   ],
   "source": [
    "answers = generate_answers(description, questions)\n",
    "\n",
    "for question, answer in zip(questions, answers):\n",
    "    print(f\"Question: {question}\")\n",
    "    print(f\"Answer: {answer}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "nltk.download('punkt')\n",
    "\n",
    "# Takes chunk is little less than 150 tokens\n",
    "def chunk_text(text, max_chars=300, overlap=10):\n",
    "    sentences = sent_tokenize(text)\n",
    "    chunks = []\n",
    "    current_chunk = \"\"\n",
    "\n",
    "    for sentence in sentences:\n",
    "        if len(current_chunk) + len(sentence) <= max_chars:\n",
    "            current_chunk += sentence + \" \"\n",
    "        else:\n",
    "            if current_chunk:\n",
    "                chunks.append(current_chunk.strip())\n",
    "            current_chunk = sentence + \" \"\n",
    "            \n",
    "            # If the sentence itself exceeds max_chars, split it\n",
    "            while len(current_chunk) > max_chars:  \n",
    "                # 100 char tolerance for long sentences\n",
    "                if len(sentence.strip()) <= max_chars+100:\n",
    "                    break    \n",
    "\n",
    "                chunks.append(current_chunk[:max_chars])\n",
    "                current_chunk = current_chunk[max_chars-overlap:] + \" \"\n",
    "\n",
    "    if current_chunk:\n",
    "        chunks.append(current_chunk.strip())\n",
    "\n",
    "    return chunks\n",
    "\n",
    "import re\n",
    "\n",
    "\n",
    "def token_count(text):\n",
    "    words = word_tokenize(text)\n",
    "    return len(words)\n",
    "\n",
    "# 150 tokens per chunk\n",
    "def chunk_text(text, max_tokens=80, overlap=5):\n",
    "    sentences = sent_tokenize(text)\n",
    "    chunks = []\n",
    "    current_chunk = \"\"\n",
    "    current_chunk_tokens = 0\n",
    "\n",
    "    for sentence in sentences:\n",
    "        sentence_tokens = token_count(sentence)\n",
    "        \n",
    "        if current_chunk_tokens + sentence_tokens <= max_tokens:\n",
    "            current_chunk += sentence + \" \"\n",
    "            current_chunk_tokens += sentence_tokens\n",
    "        else:\n",
    "            if current_chunk:\n",
    "                chunks.append(current_chunk.strip())\n",
    "            current_chunk = sentence + \" \"\n",
    "            current_chunk_tokens = sentence_tokens\n",
    "            \n",
    "            # If the sentence itself exceeds max_tokens, split it\n",
    "            while current_chunk_tokens > max_tokens:\n",
    "                # 40 token tolerance for long sentences\n",
    "                if current_chunk_tokens <= max_tokens + 40:\n",
    "                    break\n",
    "                \n",
    "                words = re.findall(r'\\S+', current_chunk)\n",
    "                chunk = \" \".join(words[:max_tokens])\n",
    "                chunks.append(chunk)\n",
    "                current_chunk = \" \".join(words[max_tokens-overlap:]) + \" \"\n",
    "                current_chunk_tokens = len(words[max_tokens-overlap:])\n",
    "\n",
    "    if current_chunk:\n",
    "        chunks.append(current_chunk.strip())\n",
    "\n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python312\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\mukoo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU detected and being used.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python312\\Lib\\site-packages\\transformers\\models\\bart\\modeling_bart.py:497: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at ..\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:263.)\n",
      "  attn_output = torch.nn.functional.scaled_dot_product_attention(\n",
      "You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.chat_models import ChatOllama\n",
    "from transformers import pipeline\n",
    "import torch\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "\n",
    "\n",
    "nltk.download('punkt')\n",
    "\n",
    "def token_count(text):\n",
    "    words = word_tokenize(text)\n",
    "    return len(words)\n",
    "\n",
    "# 100 tokens per chunk\n",
    "def chunk_text(text, max_tokens=80, overlap=8):\n",
    "    sentences = sent_tokenize(text)\n",
    "    chunks = []\n",
    "    current_chunk = \"\"\n",
    "    current_chunk_tokens = 0\n",
    "\n",
    "    for sentence in sentences:\n",
    "        sentence_tokens = token_count(sentence)\n",
    "        \n",
    "        if current_chunk_tokens + sentence_tokens <= max_tokens:\n",
    "            current_chunk += sentence + \" \"\n",
    "            current_chunk_tokens += sentence_tokens\n",
    "        else:\n",
    "            if current_chunk:\n",
    "                chunks.append(current_chunk.strip())\n",
    "            current_chunk = sentence + \" \"\n",
    "            current_chunk_tokens = sentence_tokens\n",
    "            \n",
    "            # If the sentence itself exceeds max_tokens, split it\n",
    "            while current_chunk_tokens > max_tokens:\n",
    "                # Token tolerance for long sentences\n",
    "                if current_chunk_tokens <= max_tokens + max_tokens/2.1:\n",
    "                   break                \n",
    "                words = re.findall(r'\\S+', current_chunk)\n",
    "                chunk = \" \".join(words[:max_tokens])\n",
    "                chunks.append(chunk)\n",
    "                current_chunk = \" \".join(words[max_tokens-overlap:]) + \" \"\n",
    "                current_chunk_tokens = len(words[max_tokens-overlap:])\n",
    "\n",
    "    if current_chunk:\n",
    "        chunks.append(current_chunk.strip())\n",
    "\n",
    "    return chunks\n",
    "\n",
    "\n",
    "def check_hallucination(nli_model, chunk, description):\n",
    "    result = nli_model(chunk, [description], hypothesis_template=\"This text is true: {}\")\n",
    "    # print(result[\"scores\"])\n",
    "    # print(chunk)\n",
    "    # print()\n",
    "    return result['scores'][0] < 0.85\n",
    "\n",
    "def regenerate_answer(llm, chunks, description, question, answer):\n",
    "    prompt = f\"\"\"\n",
    "    Company Description: \"\"{description}\"\"\n",
    "\n",
    "    Question: \"\"{question}\"\"\n",
    "\n",
    "    Here is the previous answer:\n",
    "    \"\"{answer}\"\"\n",
    "\n",
    "    The following chunks of text from the previous answer may contain hallucinations:\n",
    "    \"\"{chunks}\"\"\n",
    "\n",
    "    Please rewrite the answer without any hallucinations, ensuring it is firmly grounded in the company description provided. If you cannot rewrite it accurately based on the given information, respond with 'Information not provided'.\n",
    "\n",
    "    REQUIREMENTS:\n",
    "    - Be concise and relevant.\n",
    "    - Do not include any disclaimers or self-references.\n",
    "    - Act as though you are the company representative trying to inform about your company.\n",
    "    - Provide only plain text without formatting or special characters.\n",
    "    - Be descriptive and provide concrete detail, but only if it's supported by the company description.\n",
    "    - VERY IMPORTANT: Be sure to rewrite or omit the chunks marked as hallucinations! For rewritten chunks, ensure that the answer is firmly grounded in the company description.\n",
    "    \"\"\"\n",
    "    return llm.invoke(prompt).content\n",
    "\n",
    "def generate_answers(description, questions):\n",
    "    llm = ChatOllama(model=\"llama3.1\", device=\"cuda\", temperature=0)\n",
    "    nli_model = pipeline(\"zero-shot-classification\", model=\"facebook/bart-large-mnli\", device=0 if torch.cuda.is_available() else -1)\n",
    "    no_info = \"Information not provided\"\n",
    "    description_chunks = chunk_text(description, 600, 10)\n",
    "    answers = []\n",
    "\n",
    "    try:\n",
    "        for question in questions:\n",
    "            prompt = f\"\"\"\n",
    "            Company Description: \"\"{description}\"\"\n",
    "\n",
    "            Question: \"\"{question}\"\"\n",
    "\n",
    "            FOLLOW THESE REQUIREMENTS:\n",
    "            - Please provide a concise and relevant answer to the question based on the company description as if you are the company representative answering it.\n",
    "            - Do not say you are 'attempting' to answer the question or provide any other disclaimers.\n",
    "            - Do not make any references to yourself or use 'I', 'us', 'we', or any personal pronouns.\n",
    "            - Use accurate and precise language and information based on the company description.\n",
    "            - If you do not have enough information to answer the question, output 'Information not provided'.\n",
    "            - If you are not sure about specific technical details, avoid making them up or mentioning them.\n",
    "            - If you lack enough details that you cannot provide an answer firmly based in the company description, output 'Information not provided'.\n",
    "            - Act as though you are the company representative trying to inform about your company.\n",
    "            - Everything should be in plain text. Do not include any formatting or special characters.\n",
    "            - Be descriptive and provide concrete detail.\n",
    "            \"\"\"\n",
    "\n",
    "            answer = llm.invoke(prompt).content\n",
    "\n",
    "            for attempts in range(3):\n",
    "                chunks = chunk_text(answer)\n",
    "                bad_chunks = []\n",
    "\n",
    "                for chunk in chunks:\n",
    "                    bad_one = True\n",
    "                    for description_chunk in description_chunks:\n",
    "                        if not check_hallucination(nli_model, chunk, description_chunk):\n",
    "                            bad_one = False\n",
    "                            break\n",
    "                        \n",
    "                    if bad_one:\n",
    "                        bad_chunks.append(chunk)\n",
    "\n",
    "                if not bad_chunks:\n",
    "                    break\n",
    "                elif attempts == 2:\n",
    "                    answer = no_info\n",
    "                    break\n",
    "                else:\n",
    "                    answer = regenerate_answer(llm, \"\\n\".join(bad_chunks), description, question, answer)\n",
    "\n",
    "            answers.append(answer)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error generating answers: {e}\")\n",
    "        answers = [\"Error generating answer\" for _ in questions]\n",
    "\n",
    "    return answers\n",
    "\n",
    "gpu_check()\n",
    "answers = generate_answers(description, questions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: What is the elevator pitch?\n",
      "Answer: At TerrorToys, we specialize in crafting the most thrillingly dangerous toys that push the boundaries of fun and fear. Our products are engineered to thrill, shock, and sometimes even harm, blending cutting-edge technology with menacing designs. We offer a range of extreme experiences, from remote-controlled mini-tanks equipped with miniature flamethrowers to interactive robots with sharp metal claws. Our mission is to provide an adrenaline rush for those brave enough to play, while cleverly marketing our products as novelty items for collectors and framing them as rare artifacts for the bold few.\n",
      "\n",
      "Question: What problem is the company solving?\n",
      "Answer: The problem that TerrorToys is solving is the lack of excitement and thrill in modern toys, which have become too soft and sanitized for some consumers. By creating toys that are engineered to be thrillingly dangerous, TerrorToys is catering to a niche market of fearless thrill-seekers who crave unpredictability and a touch of danger in their entertainment.\n",
      "\n",
      "Question: What is the company's solution to the problem they are solving?\n",
      "Answer: Our solution to the problem of a world that has become too soft and sanitized is to create toys that offer an extreme experience, pushing the boundaries of fun and fear. We design and manufacture products like remote-controlled mini-tanks with flamethrowers, interactive robots with sharp metal claws, and action figures that can spring to life with a terrifying hiss. These toys are engineered to thrill, shock, and sometimes even harm, providing an adrenaline rush for those brave enough to play.\n",
      "\n",
      "Our marketing team cleverly positions these products as \"extreme experiences\" rather than hazardous items, using slogans like \"Unleash the Chaos\" and \"For Kids Who Like Their Fun Dangerous.\" We target fearless thrill-seekers through strategic placements in extreme sports media, horror movie forums, and underground gaming communities. Our social media campaigns highlight real-life \"missions\" where our toys play a starring role, often featuring high-energy stunts or daring challenges.\n",
      "\n",
      "By framing our products as novelty items for collectors, we cleverly avoid liability issues and generate a sense of scarcity, increasing demand among risk-takers who want to possess a piece of true danger. This approach allows us to capitalize on the desire for unpredictability in today's climate of over-protection.\n",
      "\n",
      "Question: How is the company's solution defensible in the marketplace?\n",
      "Answer: The company's solution is defensible in the marketplace due to its unique blend of cutting-edge technology, menacing designs, and expert marketing. By positioning our toys as \"extreme experiences\" rather than hazardous products, we've created a niche market that appeals to a rebellious crowd looking for thrills.\n",
      "\n",
      "Our marketing team has mastered the art of spin, carefully crafting ads and social media campaigns that highlight the excitement and unpredictability of our toys. Strategic placements in extreme sports media, horror movie forums, and underground gaming communities have helped us build a loyal fanbase of fearless thrill-seekers.\n",
      "\n",
      "Furthermore, we've cleverly avoided liability issues by framing our products as novelty items for collectors, generating a sense of scarcity through limited editions and exclusivity. This tactic has increased demand among risk-takers who want to possess a piece of true danger.\n",
      "\n",
      "Ultimately, the company's solution is defensible because it taps into a desire for excitement and unpredictability that exists in the market, while also cleverly managing potential risks and liabilities.\n",
      "\n",
      "Question: What are the patent details?\n",
      "Answer: The patent details for TerrorToys' products are not explicitly mentioned in our company description. However, it can be inferred that the company holds patents for their unique and innovative designs, such as remote-controlled mini-tanks equipped with miniature flamethrowers, interactive robots with sharp metal claws, and other similarly complex toys.\n",
      "\n",
      "These patented products showcase the company's commitment to pushing the boundaries of fun and fear, combining cutting-edge technology with menacing designs. The specific patent details, including patent numbers, filing dates, and expiration dates, are not provided in our company description.\n",
      "\n",
      "Question: What risks does the company face?\n",
      "Answer: The company faces risks associated with the safety of its products, which can seriously injure users. The use of cutting-edge technology and menacing designs in toys like remote-controlled mini-tanks equipped with miniature flamethrowers, interactive robots with sharp metal claws, and action figures that can spring to life with a terrifying hiss poses a significant risk to consumers.\n",
      "\n",
      "Additionally, the company's marketing strategy, which positions its products as \"extreme experiences\" rather than hazardous products, may be seen as deceptive or misleading by some. The use of slogans like \"Unleash the Chaos\" and \"For Kids Who Like Their Fun Dangerous\" could be perceived as encouraging reckless behavior in children.\n",
      "\n",
      "Furthermore, the company's tactics to avoid liability issues by framing its products as novelty items for collectors may not be effective in all cases, and the company could still face lawsuits or other legal consequences if someone is injured while using one of its toys.\n",
      "\n",
      "Question: How did the company discover their customers?\n",
      "Answer: The company discovered its customers through strategic marketing efforts. The elite marketing team targeted extreme sports media, horror movie forums, and underground gaming communities to reach a fanbase of fearless thrill-seekers. Social media campaigns were also used to highlight real-life \"missions\" where the toys played a starring role, often featuring high-energy stunts or daring challenges. Additionally, clever partnerships with influencers who enjoy pushing the limits, such as skydivers, stunt artists, and extreme chefs, brought the toys into the limelight.\n",
      "\n",
      "Question: What is the customer description?\n",
      "Answer: The customer description for TerrorToys is a group of fearless thrill-seekers who crave the unpredictable and are looking for extreme experiences. They are drawn to our toys because they offer an adrenaline rush, shock, and sometimes even harm. This demographic includes fans of extreme sports, horror movies, underground gaming communities, and individuals who enjoy pushing the limits. They are attracted to our marketing campaigns that highlight real-life \"missions\" featuring high-energy stunts or daring challenges, and often coincide with viral stunts that leave the world buzzing with excitement.\n",
      "\n",
      "Question: What is the customer acquisition strategy?\n",
      "Answer: Our customer acquisition strategy involves strategic placements of our marketing efforts in extreme sports media, horror movie forums, and underground gaming communities. We target fearless thrill-seekers through social media campaigns that highlight real-life \"missions\" featuring high-energy stunts or daring challenges. Our toy launches often coincide with viral stunts that leave the world buzzing with excitement. Additionally, we partner with influencers who enjoy pushing the limits, such as skydivers, stunt artists, and extreme chefs, to bring our toys into the limelight. By framing our products as novelty items for collectors through limited editions and exclusivity, we generate a sense of scarcity among risk-takers who want to possess a piece of true danger.\n",
      "\n",
      "Question: What is the company's revenue model?\n",
      "Answer: Our revenue model is primarily driven by the sales of our unique and thrilling toys, which cater to a niche market of thrill-seekers and extreme enthusiasts. We generate revenue through the direct sale of these products, often in limited editions or exclusive releases, which creates a sense of scarcity and demand among collectors.\n",
      "\n",
      "Additionally, we monetize our brand through strategic partnerships with influencers who enjoy pushing the limits, such as skydivers, stunt artists, and extreme chefs. These collaborations help to promote our toys and create viral stunts that generate buzz and excitement around our products.\n",
      "\n",
      "Furthermore, our marketing team cleverly positions our products as \"extreme experiences\" rather than hazardous items, which allows us to tap into a broader market of customers who are looking for thrills and adrenaline rushes. This approach enables us to sell our toys at a premium price point, further contributing to our revenue growth.\n",
      "\n",
      "Question: What is the market opportunity for the company?\n",
      "Answer: The market opportunity for TerrorToys lies in catering to a niche audience of thrill-seekers who crave extreme experiences and are willing to take risks. This demographic is drawn to the company's unique blend of cutting-edge technology, menacing designs, and raw adrenaline-fueled entertainment. By positioning its products as \"extreme experiences\" rather than hazardous toys, TerrorToys has successfully tapped into a market that values unpredictability and danger.\n",
      "\n",
      "The company's strategic marketing efforts have created a loyal fanbase among extreme sports enthusiasts, horror movie fans, and underground gamers who are eager to push the limits of what is considered acceptable. Social media campaigns, influencer partnerships, and limited-edition releases have all contributed to generating buzz around TerrorToys' products.\n",
      "\n",
      "Furthermore, the company's ability to cleverly avoid liability issues by framing its products as novelty items for collectors has allowed it to tap into a market that values exclusivity and rarity. This approach has created a sense of scarcity among risk-takers who are willing to pay a premium for a piece of true danger.\n",
      "\n",
      "Overall, TerrorToys' unique value proposition and targeted marketing efforts have created a significant market opportunity in the niche segment of thrill-seekers and extreme enthusiasts.\n",
      "\n",
      "Question: What is the company's competitive landscape?\n",
      "Answer: The competitive landscape of TerrorToys is characterized by a niche market that caters to thrill-seekers and those who crave extreme experiences. Our main competitors are other toy manufacturers that offer high-tech, adrenaline-pumping products, but they often shy away from the level of danger and unpredictability that we proudly promote.\n",
      "\n",
      "In this space, there are a few key players that attempt to replicate our unique blend of cutting-edge technology and menacing designs. However, their efforts are often watered down by concerns for safety and liability, which dilutes the thrill factor that sets us apart.\n",
      "\n",
      "Our marketing strategy has allowed us to carve out a distinct niche within this competitive landscape, targeting extreme sports enthusiasts, horror movie fans, and underground gamers who appreciate the raw, unbridled excitement of our products. By positioning ourselves as purveyors of \"extreme experiences\" rather than hazardous toys, we've managed to create a loyal following among those who crave the thrill of unpredictability.\n",
      "\n",
      "In terms of specific competitors, there are a few notable players that attempt to offer similar products, but they often lack the same level of sophistication and marketing savvy that sets us apart. These include companies like \"ThrillMasters\" and \"DangerZone Toys,\" which try to replicate our unique blend of technology and menace, but ultimately fall short in terms of their ability to deliver a truly immersive and thrilling experience.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for question, answer in zip(questions, answers):\n",
    "    print(f\"Question: {question}\")\n",
    "    print(f\"Answer: {answer}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_answers(description, questions):\n",
    "    llm = ChatOllama(model=\"llama3.1\", device=\"cuda\", temperature=0)\n",
    "    answers = []\n",
    "\n",
    "    try:\n",
    "        for question in questions:\n",
    "            prompt = f\"\"\"\n",
    "            Company Description: {description}\n",
    "\n",
    "            Question: {question}\n",
    "\n",
    "            FOLLOW THESE REQUIREMENTS:\n",
    "            - Please provide a concise and relevant answer to the question based on the company description as if you are the company representative answering it.\n",
    "            - Do not say you are 'attempting' to answer the question or provide any other disclaimers.\n",
    "            - Do not make any references to yourself.\n",
    "            - If you do not have enough information to answer the question, output 'Information not provided'.\n",
    "            - If you are not sure about specific technical details, avoid making them up or mentioning them. If you lack enough details that you cannot provide an answer firmly based in the company description, output 'Information not provided'.\n",
    "            - Simply provide the answer in passive voice as if you are the company representative.\n",
    "            - Everything should be in plain text. Do not include any formatting or special characters.\n",
    "            - Be descriptive and provide concrete detail.\n",
    "            \"\"\"\n",
    "            answer = llm.invoke(prompt)\n",
    "            answers.append(answer.content)\n",
    "            # answer = \"This is a placeholder answer\"\n",
    "            # answers.append(answer)\n",
    "    except Exception as e:\n",
    "        st.error(f\"Error generating answers: {e}\")\n",
    "        answers = [\"Error generating answer\" for _ in questions]\n",
    "\n",
    "    return answers"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
